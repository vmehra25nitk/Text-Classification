{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get stop-words and puctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "punctuation = [' ', '!', '(', ')', '()', '-', '[', ']', '[]', '{}', '{', '}', ';', ':', '\\', ', '<', '>', '.', '/', '?', '@', '#', '$', '%', '^', '&', '*', '_', '~']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "directory = os.listdir('20_newsgroups')\n",
    "\n",
    "for folder in directory:\n",
    "    for file in os.listdir('20_newsgroups/' + folder):\n",
    "        with open('20_newsgroups/' + folder + '/' + file, \"r\") as f_open:\n",
    "            X.append( (f_open.read()) )\n",
    "            Y.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "xTrain, xTest, yTrain, yTest = model_selection.train_test_split(X, Y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of words present in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "for i in range(len(xTrain)):\n",
    "    for word in xTrain[i].split():\n",
    "        lowWord = word.strip(string.punctuation).lower()\n",
    "        if len(lowWord) < 2:\n",
    "            continue\n",
    "        if lowWord in dictionary:\n",
    "            dictionary[lowWord] += 1\n",
    "        else:\n",
    "            dictionary[lowWord] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop-words and puctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in punctuation:\n",
    "    if word in dictionary:\n",
    "        del dictionary[word]\n",
    "for word in stopWords:\n",
    "    if word in dictionary:\n",
    "        del dictionary[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove less frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutOff = 100\n",
    "wordFeature = []\n",
    "for word in dictionary.keys():\n",
    "    if dictionary[word] >= cutOff:\n",
    "        wordFeature.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordFeature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a training dataframe and a testing dataframe\n",
    "Save them in a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataframe = np.zeros((len(xTrain), len(wordFeature)))\n",
    "for i in range(len(xTrain)):\n",
    "    for word in xTrain[i].split():\n",
    "        lowWord = word.strip(string.punctuation).lower()\n",
    "        if lowWord in wordFeature:\n",
    "            trainDataframe[i][wordFeature.index(lowWord)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('trainDataframe.txt', 'wb')\n",
    "pickle.dump(trainDataframe, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataframe = np.zeros( (len(xTest), len(wordFeature)))\n",
    "for i in range(len(xTest)):\n",
    "    for word in xTest[i].split():\n",
    "        lowWord = word.strip(string.punctuation).lower()\n",
    "        if lowWord in wordFeature:\n",
    "            testDataframe[i][wordFeature.index(lowWord)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('testDataframe.txt', 'wb')\n",
    "pickle.dump(testDataframe, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for GaussianNB results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(trainDataframe, yTrain)\n",
    "yPredGauss = clf.predict(testDataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.67      0.87      0.76       261\n",
      "           comp.graphics       0.63      0.69      0.66       248\n",
      " comp.os.ms-windows.misc       0.81      0.74      0.77       253\n",
      "comp.sys.ibm.pc.hardware       0.72      0.68      0.70       260\n",
      "   comp.sys.mac.hardware       0.76      0.83      0.80       266\n",
      "          comp.windows.x       0.89      0.85      0.87       265\n",
      "            misc.forsale       0.77      0.73      0.75       252\n",
      "               rec.autos       0.77      0.78      0.78       223\n",
      "         rec.motorcycles       0.87      0.90      0.88       293\n",
      "      rec.sport.baseball       0.89      0.90      0.90       245\n",
      "        rec.sport.hockey       0.91      0.93      0.92       247\n",
      "               sci.crypt       0.86      0.91      0.89       248\n",
      "         sci.electronics       0.75      0.80      0.78       239\n",
      "                 sci.med       0.88      0.85      0.87       236\n",
      "               sci.space       0.78      0.81      0.80       238\n",
      "  soc.religion.christian       0.95      0.95      0.95       233\n",
      "      talk.politics.guns       0.74      0.79      0.77       255\n",
      "   talk.politics.mideast       0.92      0.88      0.90       258\n",
      "      talk.politics.misc       0.51      0.42      0.46       228\n",
      "      talk.religion.misc       0.59      0.41      0.48       252\n",
      "\n",
      "             avg / total       0.79      0.79      0.78      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest, yPredGauss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own Naive Bayes Classifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ownNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.dictn = {}\n",
    "        self.cls = []\n",
    "        \n",
    "    def fit(self, xTrain, yTrain):\n",
    "        self.cls = set(yTrain)\n",
    "        for cl in self.cls:\n",
    "            self.dictn[cl] = {}\n",
    "            for k in range(len(xTrain[0])):\n",
    "                self.dictn[cl][k] = 0\n",
    "            self.dictn[cl]['classCnt'] = 0\n",
    "            self.dictn[cl]['totWordCnt'] = 0\n",
    "        self.dictn['totalCnt'] = len(yTrain)\n",
    "        \n",
    "        for classIndex in range(len(xTrain)):\n",
    "            for wordIndex in range(len(xTrain[0])):\n",
    "                self.dictn[yTrain[classIndex]][wordIndex] += xTrain[classIndex][wordIndex]\n",
    "                self.dictn[yTrain[classIndex]]['totWordCnt'] += xTrain[classIndex][wordIndex]\n",
    "            self.dictn[yTrain[classIndex]]['classCnt'] += 1\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def getAnsSinglePoint(self, xSingle):\n",
    "        ans = \"\"\n",
    "        maxProb = -10000000\n",
    "        \n",
    "        for cl in self.cls:\n",
    "            curProb = np.log(self.dictn[cl]['classCnt']) - np.log(self.dictn['totalCnt']) \n",
    "            #  self.dictn[cl]['classCnt']/self.dictn['totalCnt']\n",
    "            for i in range(len(xSingle)):\n",
    "                curProb += ( np.log(self.dictn[cl][i] + 1) - np.log(self.dictn[cl]['totWordCnt'] + len(xSingle)) ) * xSingle[i]\n",
    "            if(curProb > maxProb):\n",
    "                maxProb = curProb\n",
    "                ans = cl\n",
    "        \n",
    "        return ans\n",
    "    \n",
    "    def predict(self, xTest):\n",
    "        yPredTest = []\n",
    "        for i in range(len(xTest)):\n",
    "            yPredTest.append(self.getAnsSinglePoint(xTest[i]))\n",
    "        return yPredTest\n",
    "              \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"trainDataframe.txt\", 'rb')\n",
    "trainDataframe = pickle.load(pickle_in)\n",
    "pickle_in = open(\"testDataframe.txt\", 'rb')\n",
    "testDataframe = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ownNaiveBayes()\n",
    "clf.fit(trainDataframe, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredOwn = clf.predict(testDataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.84      0.78       261\n",
      "           comp.graphics       0.76      0.82      0.79       248\n",
      " comp.os.ms-windows.misc       0.87      0.84      0.85       253\n",
      "comp.sys.ibm.pc.hardware       0.82      0.84      0.83       260\n",
      "   comp.sys.mac.hardware       0.89      0.91      0.90       266\n",
      "          comp.windows.x       0.93      0.83      0.88       265\n",
      "            misc.forsale       0.81      0.89      0.85       252\n",
      "               rec.autos       0.86      0.89      0.87       223\n",
      "         rec.motorcycles       0.92      0.96      0.94       293\n",
      "      rec.sport.baseball       0.96      0.96      0.96       245\n",
      "        rec.sport.hockey       0.98      0.97      0.98       247\n",
      "               sci.crypt       0.95      0.90      0.92       248\n",
      "         sci.electronics       0.83      0.90      0.86       239\n",
      "                 sci.med       0.97      0.90      0.94       236\n",
      "               sci.space       0.91      0.94      0.93       238\n",
      "  soc.religion.christian       0.93      0.99      0.96       233\n",
      "      talk.politics.guns       0.79      0.88      0.83       255\n",
      "   talk.politics.mideast       0.95      0.86      0.91       258\n",
      "      talk.politics.misc       0.72      0.67      0.69       228\n",
      "      talk.religion.misc       0.69      0.45      0.55       252\n",
      "\n",
      "             avg / total       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest, yPredOwn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
